Searching for duplicates in ../../bbb/

   2.5    GB wasted by duplicates of ../../bbb/big_buck_bunny_1080p_stereo.ogg:
../../bbb/big_buck_bunny_1080p_stereo.ogg_COPY_1
../../bbb/big_buck_bunny_1080p_stereo.ogg_COPY_3
../../bbb/big_buck_bunny_1080p_stereo.ogg_COPY_2

   2.5    GB wasted in total
Filename: dedup.py

Line #    Mem usage    Increment   Line Contents
================================================
    61    9.895 MiB    0.000 MiB       @profile
    62                                 def identical(self, fileEntry):
    63  876.719 MiB  866.824 MiB           me = open(self._path).read()
    64 1738.934 MiB  862.215 MiB           him= open(fileEntry.path()).read()
    65 1738.934 MiB    0.000 MiB           return me == him


Filename: dedup.py

Line #    Mem usage    Increment   Line Contents
================================================
    43    9.895 MiB    0.000 MiB       @profile
    44                                 def __init__(self, root, target):
    45    9.895 MiB    0.000 MiB           self._path = os.path.join(root, target)
    46    9.895 MiB    0.000 MiB           self._size = os.stat(self._path).st_size
    47  876.719 MiB  866.824 MiB           content = open(self._path).read()
    48  876.719 MiB    0.000 MiB           self._csum = hashlib.md5(content).hexdigest()
    49  876.719 MiB    0.000 MiB           self._duplicates = []


